# Quickstart Guide: AI Vector Memory

**Feature**: 006-vector-memory
**Audience**: Developers implementing or maintaining this feature
**Last Updated**: 2026-01-25

## Deprecation Notice

**Automatic Context Retrieval Removed**: The automatic context retrieval feature (MemoryContext component, useContextRetrieval hook) has been removed. This guide now focuses on manual search functionality only. See the plan.md deprecation notice for details.

## Overview

This guide provides a quick reference for working with the AI vector memory system. The system enables manual semantic search across journal entries using client-side embeddings generated by the all-MiniLM-L6-v2 model running in a Web Worker.

## Architecture at a Glance

```
User Message
    ↓
Embedding Worker (Web Worker)
    ↓ (generates 384-dim vector)
Embedding Service
    ↓ (stores in RxDB)
Embeddings Collection (encrypted)
    ↓ (query on search)
Memory Service (cosine similarity)
    ↓ (retrieves messages)
Search Results
```

## Key Components

| Component | Location | Purpose |
|-----------|----------|---------|
| `EmbeddingService` | `src/services/embedding/generator.ts` | Generates embeddings from text |
| `embedding.worker.ts` | `src/services/embedding/worker.ts` | Off-thread ML model execution |
| `MemoryService` | `src/services/memory/search.ts` | Semantic search implementation |
| `MemoryIndexer` | `src/services/memory/indexer.ts` | Manages embedding lifecycle |
| `embeddingSchema` | `src/db/schemas/embedding.schema.ts` | RxDB schema for vectors |
| `useMemorySearch` | `src/hooks/useMemorySearch.ts` | React hook for search UI |
| `MemorySearch` | `src/components/search/MemorySearch.tsx` | Manual search dialog |

## Quick Setup

### 1. Install Dependencies

```bash
npm install @xenova/transformers
```

### 2. Initialize Database Collection

The `embeddings` collection is automatically created when the database initializes (see `src/db/index.ts`):

```typescript
await db.addCollections({
  // ... existing collections
  embeddings: {
    schema: embeddingSchema,
  },
});
```

### 3. Initialize Embedding Service

In your app initialization:

```typescript
import { embeddingService } from '@/services/embedding/generator';

// Initialize service (loads model)
await embeddingService.initialize();
```

### 4. Index Messages

When a new message is created:

```typescript
import { memoryIndexer } from '@/services/memory/indexer';

// Queue for embedding (non-blocking)
memoryIndexer.queueForEmbedding(message.id);

// Process queue in background
memoryIndexer.processQueue();
```

## Common Operations

### Search Journal Entries

```typescript
import { memoryService } from '@/services/memory/search';

const results = await memoryService.search({
  query: 'times I felt anxious',
  limit: 10,
  minScore: 0.5, // Only results >50% similar
});

results.forEach(result => {
  console.log(result.message.content); // Matching message
  console.log(result.score); // Similarity score (0-1)
  console.log(result.excerpt); // Preview text
});
```

### Manual Embedding Generation

```typescript
import { embeddingService } from '@/services/embedding/generator';

const result = await embeddingService.generateEmbedding(
  'Sample text to embed'
);

console.log(result.vector); // Float32Array(384)
console.log(result.modelVersion); // 'all-MiniLM-L6-v2@v0'
console.log(result.processingTimeMs); // e.g., 45
```

### Check Index Status

```typescript
import { memoryService } from '@/services/memory/search';

const stats = await memoryService.getIndexStats();

console.log(stats.totalMessages); // e.g., 1247
console.log(stats.indexedMessages); // e.g., 1240
console.log(stats.pendingMessages); // e.g., 7
console.log(stats.modelVersion); // 'all-MiniLM-L6-v2@v0'
```

## React Hook Usage

### Manual Search in UI

```tsx
import { useMemorySearch } from '@/hooks/useMemorySearch';

function SearchDialog() {
  const { results, isSearching, search, clear } = useMemorySearch();

  const handleSearch = async (query: string) => {
    await search({ query, limit: 10 });
  };

  return (
    <div>
      <SearchInput onSearch={handleSearch} />
      {isSearching && <Spinner />}
      {results.map(result => (
        <ResultCard key={result.message.id} result={result} />
      ))}
    </div>
  );
}
```

## Performance Tips

### 1. Use Web Worker (Already Implemented)
Embedding generation runs in a Web Worker to keep UI responsive. Don't bypass this:

```typescript
// ✅ Good: Uses worker
await embeddingService.generateEmbedding(text);

// ❌ Bad: Blocks main thread
// Don't import transformers.js directly in main thread
```

### 2. Batch Embed When Possible
When indexing multiple messages:

```typescript
// ✅ Good: Batch operation
const texts = messages.map(m => m.content);
const results = await embeddingService.generateBatchEmbeddings(texts);

// ❌ Avoid: Individual calls in loop
for (const message of messages) {
  await embeddingService.generateEmbedding(message.content);
}
```

### 3. Debounce Search in UI
Avoid search on every keystroke:

```typescript
// ✅ Good: Debounced search
const debouncedSearch = useMemo(
  () => debounce((query) => search({ query }), 300),
  []
);

// ❌ Bad: Search on every onChange
onChange={(e) => search({ query: e.target.value })}
```

### 4. Lazy Load Index
Don't load all embeddings on app start:

```typescript
// ✅ Good: Load on search
async search(query: MemorySearchQuery) {
  const embeddings = await db.embeddings.find().exec();
  // ... perform search
}

// ❌ Bad: Load all embeddings globally
const allEmbeddings = await db.embeddings.find().exec(); // On init
```

## Testing

### Unit Test: Embedding Generation

```typescript
import { embeddingService } from '@/services/embedding/generator';

test('generates normalized 384-dim embeddings', async () => {
  await embeddingService.initialize();

  const result = await embeddingService.generateEmbedding('test text');

  expect(result.vector).toHaveLength(384);
  expect(result.modelVersion).toBe('all-MiniLM-L6-v2@v0');

  // Check normalization (sum of squares ≈ 1)
  const sumOfSquares = result.vector.reduce(
    (sum, val) => sum + val * val,
    0
  );
  expect(Math.abs(sumOfSquares - 1.0)).toBeLessThan(0.01);
});
```

### Unit Test: Similarity Search

```typescript
import { computeSimilarity } from '@/services/memory/search';

test('cosine similarity returns correct scores', () => {
  const v1 = new Float32Array([1, 0, 0]);
  const v2 = new Float32Array([1, 0, 0]); // Identical
  const v3 = new Float32Array([0, 1, 0]); // Orthogonal

  expect(computeSimilarity(v1, v2)).toBeCloseTo(1.0); // Perfect match
  expect(computeSimilarity(v1, v3)).toBeCloseTo(0.0); // No match
});
```

### Integration Test: End-to-End Search

```typescript
import { memoryService } from '@/services/memory/search';
import { createDatabase } from '@/db';

test('search returns relevant messages', async () => {
  const db = await createDatabase('test-pass');

  // Create test messages
  await db.messages.insert({
    id: '1',
    content: 'I felt anxious about the presentation',
    // ... other fields
  });

  await db.messages.insert({
    id: '2',
    content: 'The presentation went really well',
    // ... other fields
  });

  // Index messages
  await memoryIndexer.queueForEmbedding('1');
  await memoryIndexer.queueForEmbedding('2');
  await memoryIndexer.processQueue();

  // Search
  const results = await memoryService.search({
    query: 'anxiety before presenting',
    limit: 5,
  });

  expect(results[0].message.id).toBe('1'); // Most relevant
  expect(results[0].score).toBeGreaterThan(0.6);
});
```

## Debugging

### Check Service Status

```typescript
const status = embeddingService.getStatus();
console.log(status);
// {
//   isReady: true,
//   model: 'Xenova/all-MiniLM-L6-v2',
//   version: 'all-MiniLM-L6-v2@v0',
//   device: 'webgpu',
//   isLoading: false
// }
```

### Inspect Embeddings in Database

```typescript
const embedding = await db.embeddings.findOne({
  selector: { messageId: 'abc-123' }
}).exec();

console.log(embedding.vector.length); // 384
console.log(embedding.modelVersion); // 'all-MiniLM-L6-v2@v0'
console.log(new Date(embedding.createdAt)); // When created
```

### Monitor Embedding Queue

```typescript
const queueLength = memoryIndexer.getQueueLength();
console.log(`${queueLength} messages pending embedding`);
```

### Cleanup Orphaned Embeddings

```typescript
const removed = await memoryIndexer.cleanupOrphans();
console.log(`Removed ${removed} orphaned embeddings`);
```

## Common Issues

### Issue: Model Not Loading

**Symptom**: `embeddingService.initialize()` hangs or times out

**Solutions**:
1. Check network connection (model downloads from HuggingFace CDN)
2. Clear browser cache (corrupted cached model)
3. Check browser console for CORS/network errors
4. Verify WebAssembly is enabled in browser

### Issue: Slow Embedding Generation

**Symptom**: Embeddings take >1 second per message

**Solutions**:
1. Check if WebGPU is available: `navigator.gpu !== undefined`
2. Fallback to WASM is slower (expected 50-150ms vs 20-50ms)
3. Ensure embedding runs in Web Worker (check service implementation)
4. Consider batching multiple embeddings together

### Issue: Search Returns Irrelevant Results

**Symptom**: Low similarity scores or unexpected matches

**Solutions**:
1. Check query length - very short queries (<5 words) less accurate
2. Verify embeddings are normalized (sum of squares ≈ 1.0)
3. Adjust `minScore` threshold (default 0.5)
4. Check for mixed model versions in index (run `rebuildIndex()`)

### Issue: Memory Usage High

**Symptom**: Browser memory increases significantly

**Solutions**:
1. Don't load all embeddings into memory - query on-demand
2. Clear unused embeddings after search: `results = null`
3. Check for embedding leaks in React components (use cleanup)
4. Consider periodic `cleanupOrphans()` to remove unused embeddings

## Migration and Upgrades

### Rebuild Index After Model Upgrade

If upgrading to a new embedding model:

```typescript
import { memoryService } from '@/services/memory/search';

// This will re-embed all messages with new model
await memoryService.rebuildIndex((current, total) => {
  console.log(`Progress: ${current}/${total}`);
});
```

### Migrate from v0 to v1

When schema version increments:

```typescript
// RxDB automatically runs migrations
// Add migration handler in schema:

export const embeddingSchema: RxJsonSchema<Embedding> = {
  version: 1, // Incremented
  // ... schema
  migrationStrategies: {
    1: (oldDoc) => {
      // Transform v0 → v1
      return {
        ...oldDoc,
        newField: 'default value',
      };
    },
  },
};
```

## Further Reading

- [Implementation Plan](./plan.md) - Full technical design
- [Research Notes](./research.md) - Embedding library evaluation
- [Data Model](./data-model.md) - Database schema details
- [API Contracts](./contracts/) - TypeScript interfaces
- [Transformers.js Docs](https://huggingface.co/docs/transformers.js) - Library documentation

## Support

For questions or issues:
1. Check existing tests for usage examples
2. Review contract interfaces in `contracts/`
3. Inspect service implementation in `src/services/`
4. Refer to research notes for technical decisions
